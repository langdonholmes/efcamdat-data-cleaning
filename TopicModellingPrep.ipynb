{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a56d588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/packaging/version.py:127: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=0)\n",
    "\n",
    "from gensim.models import Phrases\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "print(spacy.__version__)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fa6958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549281\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>lvl</th>\n",
       "      <th>unit</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_nationality</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>date</th>\n",
       "      <th>grade</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C18217</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20967052</td>\n",
       "      <td>cn</td>\n",
       "      <td>Writing labels for a clothing store</td>\n",
       "      <td>22440</td>\n",
       "      <td>2012-04-20 21:12:14.890</td>\n",
       "      <td>79</td>\n",
       "      <td>Date:monday 11th.   Time:9.30 am.  From:Margar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C18541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21016113</td>\n",
       "      <td>cn</td>\n",
       "      <td>Introducing yourself by email</td>\n",
       "      <td>3535</td>\n",
       "      <td>2011-12-24 03:50:49.100</td>\n",
       "      <td>85</td>\n",
       "      <td>Dear teacher, My name's Yi Zhao,English is poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C18648</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20967075</td>\n",
       "      <td>cn</td>\n",
       "      <td>Introducing yourself by email</td>\n",
       "      <td>3535</td>\n",
       "      <td>2012-04-20 08:53:55.087</td>\n",
       "      <td>90</td>\n",
       "      <td>My name's Henry Hong,  I was born in Nanjing o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C20184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18898793</td>\n",
       "      <td>cn</td>\n",
       "      <td>Introducing yourself by email</td>\n",
       "      <td>3535</td>\n",
       "      <td>2011-12-14 08:54:48.380</td>\n",
       "      <td>95</td>\n",
       "      <td>Dear Sir, I'm Jianwen Zhang, from a little tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C20185</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18898793</td>\n",
       "      <td>cn</td>\n",
       "      <td>Taking inventory in the office</td>\n",
       "      <td>9820</td>\n",
       "      <td>2011-12-26 09:49:48.140</td>\n",
       "      <td>98</td>\n",
       "      <td>Dear Ms Thomas, There are thirteen computers a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id  lvl  unit  author_id author_nationality  \\\n",
       "0           0  C18217    1     7   20967052                 cn   \n",
       "1           1  C18541    1     1   21016113                 cn   \n",
       "2           2  C18648    1     1   20967075                 cn   \n",
       "3           3  C20184    1     1   18898793                 cn   \n",
       "4           4  C20185    1     2   18898793                 cn   \n",
       "\n",
       "                                 topic  topic_id                     date  \\\n",
       "0  Writing labels for a clothing store     22440  2012-04-20 21:12:14.890   \n",
       "1        Introducing yourself by email      3535  2011-12-24 03:50:49.100   \n",
       "2        Introducing yourself by email      3535  2012-04-20 08:53:55.087   \n",
       "3        Introducing yourself by email      3535  2011-12-14 08:54:48.380   \n",
       "4       Taking inventory in the office      9820  2011-12-26 09:49:48.140   \n",
       "\n",
       "  grade                                               text  \n",
       "0    79  Date:monday 11th.   Time:9.30 am.  From:Margar...  \n",
       "1    85  Dear teacher, My name's Yi Zhao,English is poo...  \n",
       "2    90  My name's Henry Hong,  I was born in Nanjing o...  \n",
       "3    95  Dear Sir, I'm Jianwen Zhang, from a little tow...  \n",
       "4    98  Dear Ms Thomas, There are thirteen computers a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549281\n"
     ]
    }
   ],
   "source": [
    "all_levels = pd.read_csv('all_levels.csv', low_memory=False)\n",
    "print(len(all_levels))\n",
    "display(all_levels.head())\n",
    "# display(all_levels['topic'].value_counts()) # 128 prompts\n",
    "texts = all_levels['text'].tolist()\n",
    "print(len(texts))\n",
    "\n",
    "# This elimates all student responses that are not automatically interpreted as strings by Pandas.This removes about 1,500 responses.\n",
    "# A cursory investigation suggests that all these 'non-string' responses are NaN values, so useless.\n",
    "texts = [text for text in texts if type(text) == str]\n",
    "\n",
    "texts = [re.sub(r\"\\s+\", r\" \", text) for text in texts]\n",
    "\n",
    "for i, text in enumerate(texts[0:20000]):\n",
    "    if type(text) != str:\n",
    "        print(text, i)\n",
    "# print(texts[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb9554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Run corpus through the spaCy pipeline\n",
    "\n",
    "def process_docs(texts):\n",
    "    docs = list(tqdm(nlp.pipe(texts))) # 20 minutes or so...\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c05c1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation, stop words, and digits\n",
    "# Make all words lowercase\n",
    "# We can add to the stop words list here, or use other measures to eliminate uninteresting words (TF-IDF, Dispersion)\n",
    "\n",
    "def reduce_tokens(docs):\n",
    "    processed_docs = []\n",
    "    for doc in docs:\n",
    "        processed_doc = []\n",
    "        for token in doc:\n",
    "            if not token.is_punct and not token.is_stop and not token.is_digit:\n",
    "                processed_doc.append(token.lemma_.lower())\n",
    "        processed_docs.append(processed_doc)\n",
    "    return processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70f830b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Compute bigrams.\n",
    "# Add bigrams to docs (only ones that appear 20 times or more).\n",
    "\n",
    "def compute_bigrams(processed_docs):\n",
    "    bigram = Phrases(processed_docs, min_count=20)\n",
    "    for idx in range(len(processed_docs)):\n",
    "        for token in bigram[processed_docs[idx]]:\n",
    "            if '_' in token:\n",
    "                # Token is a bigram, add to document.\n",
    "                processed_docs[idx].append(token)\n",
    "    return processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927c509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving processed corpus from file\n",
      "Retrieved\n"
     ]
    }
   ],
   "source": [
    "import os.path # Directories, gotta have em.\n",
    "\n",
    "processed_docs_filename = \"processed_docs.json\"\n",
    "\n",
    "if os.path.isfile(processed_docs_filename):\n",
    "    print('Retrieving processed corpus from file')\n",
    "    with open('processed_docs.json') as f:\n",
    "        processed_docs = json.load(f)\n",
    "    print('Retrieved')\n",
    "else:\n",
    "    print('Nothing found.')\n",
    "    spacy_docs = process_docs(texts)\n",
    "    reduced_docs = reduce_tokens(spacy_docs)\n",
    "    processed_docs = compute_bigrams(reduced_docs)\n",
    "    print('Corpus Processed.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9004d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Remove rare and common tokens.\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(processed_docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4a8efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 24919\n",
      "Number of documents: 547637\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0f60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Train LDA model.\n",
    "# Set training parameters.\n",
    "num_topics = 20\n",
    "chunksize = 600000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ab590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.print_topics())\n",
    "# doc_lda = model[corpus]\n",
    "\n",
    "p = gensimvis.prepare(model, corpus, dictionary)\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
