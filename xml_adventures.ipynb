{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c63cd0",
   "metadata": {},
   "source": [
    "# Data Wrangling Exercise\n",
    "Purpose: Classify learners by CEFR\n",
    "\n",
    "Phase 1: Wrangle some datums\n",
    "\n",
    "Notes from meeting with Scott:\n",
    "1. Consider text length\n",
    "2. Consider how representative each text is (e.g. of a given CEFR band). I am not sure if he was alluding to outliers or something else here.\n",
    "3. Methods/Technologies to consider:\n",
    "\n",
    "    a. Semantic spaces\n",
    "\n",
    "    b. LSA (this was a strong suggestion)\n",
    "\n",
    "    c. Word2Vec\n",
    "\n",
    "## Information on EFCAMDAT\n",
    "\n",
    "> EFCAMDAT consists of essays submitted to Englishtown, the online school of EF Education First, by language learners all over the world (Education First, 2012).  A full course in Englishtown spans 16 proficiency levels aligned with common standards such as TOEFL, IELTS and the Common European Framework of Reference for languages.\n",
    "\n",
    "__[Overview of EFCAMDAT Data (2013)](https://corpus.mml.cam.ac.uk/faq/SLRF2013Geertzenetal.pdf)__\n",
    "\n",
    "__[Study with recommendations for Dependency Parsing on this data set (2018)](https://corpus.mml.cam.ac.uk/faq/IJCL2018Huangetal.pdf)__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f5bc2073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: /home/jovyan/work/efcamdat\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import re\n",
    "import os.path\n",
    "import unicodedata\n",
    "\n",
    "print('Working Directory set to:', os.getcwd())\n",
    "\n",
    "test_file = os.path.join('Original Files', 'Level 4 EF_camdat.txt')\n",
    "with open(test_file, \"r\") as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b8326a",
   "metadata": {},
   "source": [
    "### One option is to manually alter each illegal character into well-formatted XML. The following script could help with that, but a full-featured text editor like Notepad++ might be a better fit for the job.\n",
    "__[Predefined characters in XML](https://en.wikipedia.org/wiki/List_of_XML_and_HTML_character_entity_references#Predefined_entities_in_XML)__ are mainly &, \", ', <, and >."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "64645ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find illegal characters in <text> groups\n",
    "# Regex makes three matching groups\n",
    "# Middle group is illegal character\n",
    "# Manual verification??\n",
    "\n",
    "# illegal_character = '&'\n",
    "# p = re.compile(r'<text>\\n+(.+)(' + illegal_character + ')(.+)\\s+<\\/text>')\n",
    "# matches = p.findall(data)\n",
    "\n",
    "# for match in matches[:2]:\n",
    "#     print(match[0])\n",
    "#     print(match[1])\n",
    "#     print(match[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbbd893",
   "metadata": {},
   "source": [
    "### Another option is to wrap every \\<TEXT\\> block in \\[\\[CDATA\\]\\] tags, which might magically make the XML properly formatted\n",
    "__[CDATA Sections in XML](https://www.tutorialspoint.com/xml/xml_cdata_sections.htm)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "eaaafe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdata_blocked_off = re.sub(r'\\s*</text>',r']]></text>', re.sub(r'<text>\\s*',r'<text><![CDATA[', data))\n",
    "\n",
    "# dump_file = os.path.join('Original Files', 'Level 2 fixing maybe.xml')\n",
    "# with open(dump_file, \"w\") as f:\n",
    "#     f.write(fixed_maybe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75665ce9",
   "metadata": {},
   "source": [
    "### This seems to work for some of the levels, but not all of them. Let's try to troubleshoot some more.\n",
    "Okay. It seems all(?) of the remaining issues are control characters. Python package unicodedata can handle this (thank you\n",
    "StackOverflow). One way to double check that this is working as expected would be to look at a git difference between\n",
    "cdata_blocked_off and controls_removed. This way we can ensure that only control characters are being removed.\n",
    "At first I thought Scott might have intentionally made this data difficult to work with, but this is way\n",
    "too crazy for anyone to have done it on purpose. One of the responses is literally just a string of control characters??\n",
    "\n",
    "The remove_control_characters function could be narrowed in scope to just the text within CDATA tags, but I am pretty sure there are no problem bytes anywhere else... therefore it would have the same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fa8101dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_control_characters(s):\n",
    "    return \"\".join(ch for ch in s if unicodedata.category(ch)[0]!=\"C\")\n",
    "\n",
    "controls_removed = remove_control_characters(cdata_blocked_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "6dfffcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = etree.fromstring(bytes(controls_removed, encoding='utf8'))\n",
    "print(\"The number of \\'samples\\' in this level {:,}:\".format(len(root[1])))\n",
    "#some of these samples are obviously useless..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "50839950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ID: C171892\n",
      "Writing Level: 4\n",
      "Writing Unit: 2\n",
      "Learner ID: 22589833\n",
      "Learner Nationality: cn\n",
      "Topic: Describing routines\n",
      "Date: 2012-05-27 10:35:40.370\n",
      "Grade: 94\n",
      "Text: Mary goes jogging in the evening every day. watches TV at 7am. does the housework in the evening. makes dinner at 7pm. washes  the dishes every day. does the ironing once a week. mops the floor in the morning. You  feed the dog at 7am in the morning. feed the dog  at 12  at noon. feed the dog at 6pm in the  afternoon. walk the dog in the afternoon. wash the dog once a week.\n"
     ]
    }
   ],
   "source": [
    "# This is not DRY...\n",
    "lvl_xml = root[1]\n",
    "isample = 99\n",
    "print('Writing ID:', lvl_xml[isample].attrib['id'])\n",
    "print('Writing Level:', lvl_xml[isample].attrib['level'])\n",
    "print('Writing Unit:', lvl_xml[isample].attrib['unit'])\n",
    "print('Learner ID:', lvl_xml[isample][0].attrib['id'])\n",
    "print('Learner Nationality:', lvl_xml[isample][0].attrib['nationality'])\n",
    "print('Topic:', lvl_xml[isample][1].text)\n",
    "print('Date:', lvl_xml[isample][2].text)\n",
    "print('Grade:', lvl_xml[isample][3].text)\n",
    "print('Text:', lvl_xml[isample][4].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36ab19",
   "metadata": {},
   "source": [
    "### This is looking good! Now we need to build a dataframe and extract the texts.\n",
    "So we have writing IDs and Learner IDs, so do not make Learner ID the index (indexes should not have duplicate entries).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1b4e9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab0cf7fb",
   "metadata": {},
   "source": [
    "### We may want to consider running a spellchecker on these responses.\n",
    "\n",
    "Maybe we...\n",
    "\n",
    "1. Eliminate useless responses. I think we can assume that all nearly-identical responses have language taken from the prompt. Even if these responses are not just echos of the prompt, I do not think they can tell us very much about the writer, since there is very little variation between them. Like most things, I'm not sure about this.\n",
    "\n",
    "    a. I think it could be fun to calculate levenshtein distance on the responses, and eliminate responses that are too similar that way.\n",
    "    \n",
    "    b. I think the more robust method would be to calculate the TF-IDF and cosine similarity, but that seems a little complex to just find responses with low variance.\n",
    "    \n",
    "2. Once we have a relatively useful subset of samples, we can bifurcate\n",
    "\n",
    "    a. Create .spacy on the samples\n",
    "    \n",
    "    b. Run spellchecker then create .spacy on a copy of the samples. This might not buy us anything, but it just might make a difference.\n",
    "    \n",
    "    **Actually, I think the best way to do this would be through spaCy.** I don't know if spaCy has an in-built spell checker, but we could add a spell checker to a custom spaCy pipeline. This would have the important advantage of preserving the original, misspelled response as well as a reasonable prediction of the intended orthography. I am not sure how we could incorporate both the uncorrected and corrected texts into a single model, but I sort of like the workflow here anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064866a",
   "metadata": {},
   "source": [
    "### Errors I've noticed\n",
    "1. Spaces before commas. I think this is **always** an error.\n",
    "2. No space after commas. I think this is an error unless the character after the comma is a quotation mark.\n",
    "3. Spaces before apostrophes/inverted commas. I think this is **always** an error.\n",
    "4. Misspellings. I suspect we can improve the data automatically by spell checking, but we of course lose information about writers' spelling knowledge.\n",
    "5. No space after periods (at end of sentence). This one is tricky. Periods should have a space when they are separating a sentence, but not when they are separating numbers (69.00 dollars) or acronyms (U.S.A.). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
